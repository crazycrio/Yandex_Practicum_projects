{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены при векторизации!\n",
    "* Работа получилась отличной, тебе удалось добиться достаточно хорошего качества. Поздравляю!\n",
    "* Проект может быть зачтен, но я его отправлю назад, чтобы у тебя была возможность задать вопросы и внести правки, при желании. Однако, ты можешь просто вернуть проект в таком же виде и я его зачту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Проект зачтен!\n",
    "* Для удобства все новые комментарии обозначены фразой \"ревью 2\".\n",
    "* Удачи в дальнейшем обучении и следующих работах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выделение-целевого-признака-и-разделение-выборок\" data-toc-modified-id=\"Выделение-целевого-признака-и-разделение-выборок-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Выделение целевого признака и разделение выборок</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым шагом выполним загрузку необходимых библиотек и инструментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку и ознакомление с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.info())\n",
    "display(comments.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделение целевого признака и разделение выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = comments['toxic']\n",
    "features = comments['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки на обущающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные к нужному типу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train.values.astype('U')\n",
    "corpus_test = features_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим в датасете только регулярные выражения. Воспользуемся методом re.sub(), применим его ко всему датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text_lem = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_train)):\n",
    "    corpus_train[i] = clear_text(corpus_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_test)):\n",
    "    corpus_test[i] = clear_text(corpus_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью стемминга приведем слова к форме основы. Воспользуемся инструментом EnglishStemmer из библиотеки nltk. Применим ко всему датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer(ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 170 ms, total: 1min 58s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(corpus_train)):\n",
    "    word_list = nltk.word_tokenize(corpus_train[i])\n",
    "    corpus_train[i] = ' '.join([stemmer.stem(w) for w in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 195 ms, total: 2min 1s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(corpus_test)):\n",
    "    word_list = nltk.word_tokenize(corpus_test[i])\n",
    "    corpus_test[i] = ' '.join([stemmer.stem(w) for w in word_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим базу стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем данные с учетом стоп-слов. Применим метод fit к обычающей выборке, а затем метод transform к обучающему и тестовому набору данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf = count_tf_idf.fit(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tf_idf.transform(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные загружены и обработаны для дальнейшего применения в обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны верно.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Но их лучше было бы сделать до разбиения выборки на части.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано правильно. Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Приводить тексты к юникоду не имеет смысла, так как они все на английском.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим несколько вариантов моделей, оценим по каждой метрику F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучать следующие модели:\n",
    "- LogisticRegression\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- Linear Support Vector Classification\n",
    "- C-Support Vector Classification\n",
    "- ExtraTreesClassifier\n",
    "- AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Еще пробовал обучать модели Linear Discriminant Analysis, Naive Bayes Classifier, K-Neighbors Classifier, Multilayer Perceptrons, BaggingClassifier, но по ним получал вылет ядра ноутбука, поэтому в финальном варианте они не участвуют.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Это из-за нехватки оперативной памяти. Неприведение к юникоду может помочь.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Понял, спасибо. Т.е. запуск на локальной машине помог бы с этим справиться?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех (ревью 2):</b> Если локалка мощнее, то да.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.58 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Оценивание эффективности выполнения каждого алгоритма\n",
    "scores = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: F1 Score = 0.720\n",
      "CPU times: user 16.5 s, sys: 20.9 s, total: 37.4 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'LR'\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(train_x, target_train)\n",
    "predictions_LR = pd.Series(model_LR.predict(test_x))\n",
    "m_score = f1_score(predictions_LR, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: F1 Score = 0.710\n",
      "CPU times: user 4min 1s, sys: 151 ms, total: 4min 1s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'CART'\n",
    "model_CART = DecisionTreeClassifier()\n",
    "model_CART.fit(train_x, target_train)\n",
    "predictions_CART = pd.Series(model_CART.predict(test_x))\n",
    "m_score = f1_score(predictions_CART, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVC: F1 Score = 0.780\n",
      "CPU times: user 652 ms, sys: 31.8 ms, total: 684 ms\n",
      "Wall time: 690 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'LSVC'\n",
    "model_LSVC = LinearSVC()\n",
    "model_LSVC.fit(train_x, target_train)\n",
    "predictions_LSVC = pd.Series(model_LSVC.predict(test_x))\n",
    "m_score = f1_score(predictions_LSVC, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: F1 Score = 0.740\n",
      "CPU times: user 29min 45s, sys: 1.22 s, total: 29min 47s\n",
      "Wall time: 30min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'SVC'\n",
    "model_SVC = SVC()\n",
    "model_SVC.fit(train_x, target_train)\n",
    "predictions_SVC = pd.Series(model_SVC.predict(test_x))\n",
    "m_score = f1_score(predictions_SVC, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: F1 Score = 0.710\n",
      "CPU times: user 5min 55s, sys: 334 ms, total: 5min 55s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'RF'\n",
    "model_RF = RandomForestClassifier()\n",
    "model_RF.fit(train_x, target_train)\n",
    "predictions_RF = pd.Series(model_RF.predict(test_x))\n",
    "m_score = f1_score(predictions_RF, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET: F1 Score = 0.720\n",
      "CPU times: user 8min 42s, sys: 1.68 s, total: 8min 44s\n",
      "Wall time: 8min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'ET'\n",
    "model_ET = ExtraTreesClassifier()\n",
    "model_ET.fit(train_x, target_train)\n",
    "predictions_ET = pd.Series(model_ET.predict(test_x))\n",
    "m_score = f1_score(predictions_ET, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: F1 Score = 0.680\n",
      "CPU times: user 30.2 s, sys: 104 ms, total: 30.3 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name = 'AB'\n",
    "model_AB = AdaBoostClassifier()\n",
    "model_AB.fit(train_x, target_train)\n",
    "predictions_AB = pd.Series(model_AB.predict(test_x))\n",
    "m_score = f1_score(predictions_AB, target_test).round(2)\n",
    "scores.append(m_score)\n",
    "names.append(name)\n",
    "msg = \"%s: F1 Score = %.3f\" % (name, m_score)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = pd.DataFrame(list(zip(names, scores)),\n",
    "               columns =['model','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSVC</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ET</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CART</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AB</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  score\n",
       "2  LSVC   0.78\n",
       "3   SVC   0.74\n",
       "0    LR   0.72\n",
       "5    ET   0.72\n",
       "1  CART   0.71\n",
       "4    RF   0.71\n",
       "6    AB   0.68"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores.sort_values(by = 'score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам обучения лучшие результаты получены у модели LinearSVC, следующим идет модель SVC, но она выполняет обучение гораздо дольше других моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Можно было подобрать параметры с помощью кросс-валидации.\n",
    "    \n",
    "Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Пробовал запускать оценку моделей по такой <a href=\"https://habr.com/ru/post/475552/\">схеме</a>, но как писал выше, часть методов у меня вылетала, да и потом сам цикл обучения моделей тоже стал крашиться, поэтому разбил пошагово подбор моделей.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет (ревью 2): </b> \n",
    "\n",
    "1. Внутри кросс-валидации происзодит разбиение переданной в нее выборку на части (треин и валидация). Подробнее тут: https://codecamp.ru/blog/cross-validation-k-fold/\n",
    "2. Мы хотим, чтобы при подборе параметров внутри кросс-валидации векторизатор не обучался на валидации. Для этого нам нужно его обучать каждый раз только на треине (внутри кросс-валидации). Для этого и нужен пайплайн, чтобы внутри кросс-валидации обучалась не только модель, но и векторизатор. \n",
    "\n",
    "Вот такой пайплайн нужно передать в кросс-валидацию:  \n",
    "`pipe_lr = Pipeline([(‘vect’, CountVectorizer()),\n",
    " (‘tfidf’, TfidfTransformer()),\n",
    " (‘model’, LogisticRegression())])`\n",
    "    \n",
    "Тут подробнее про то, как тюнить параметры у пайплайна: https://stackoverflow.com/questions/51606341/hyper-parameter-tuning-on-pipeline-object\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Данные для обучения были проверены и подготовлены для обучения;\n",
    "- Были рассмотрены несколько моделей, в топ-3 вошли модели: линейный метод опорных векторов; метод опорных векторов и линейная регрессия.\n",
    "- Для дальнейшего использования рекомендуется модель линейного метода опорных векторов, как самая быстрая и воказывающая наибольший результат по метрике F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть вывод в конце проекта!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2302,
    "start_time": "2022-05-12T18:29:24.873Z"
   },
   {
    "duration": 5961,
    "start_time": "2022-05-12T18:29:48.951Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-12T18:29:56.368Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T18:31:19.006Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-12T18:31:20.651Z"
   },
   {
    "duration": 4821,
    "start_time": "2022-05-12T18:31:42.385Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T18:32:01.057Z"
   },
   {
    "duration": 2455,
    "start_time": "2022-05-12T18:32:03.374Z"
   },
   {
    "duration": 2445,
    "start_time": "2022-05-12T18:32:10.284Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-12T18:32:17.808Z"
   },
   {
    "duration": 60914,
    "start_time": "2022-05-12T18:32:26.593Z"
   },
   {
    "duration": 60997,
    "start_time": "2022-05-12T18:33:27.509Z"
   },
   {
    "duration": 1213,
    "start_time": "2022-05-12T18:34:28.507Z"
   },
   {
    "duration": 4014,
    "start_time": "2022-05-12T18:34:29.722Z"
   },
   {
    "duration": 3914,
    "start_time": "2022-05-12T18:34:33.738Z"
   },
   {
    "duration": 3918,
    "start_time": "2022-05-12T18:34:37.654Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T18:36:59.469Z"
   },
   {
    "duration": 10874,
    "start_time": "2022-05-12T18:37:00.101Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-12T18:37:10.977Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-12T18:37:10.989Z"
   },
   {
    "duration": 185298,
    "start_time": "2022-05-12T18:39:49.142Z"
   },
   {
    "duration": 64056,
    "start_time": "2022-05-12T18:42:54.442Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T18:43:58.499Z"
   },
   {
    "duration": 290,
    "start_time": "2022-05-12T18:43:58.504Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-12T18:43:58.795Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-12T18:43:58.796Z"
   },
   {
    "duration": 2870,
    "start_time": "2022-05-12T18:47:53.748Z"
   },
   {
    "duration": 627,
    "start_time": "2022-05-12T18:47:56.619Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-12T18:47:57.248Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T18:48:26.007Z"
   },
   {
    "duration": 4017,
    "start_time": "2022-05-12T18:48:26.955Z"
   },
   {
    "duration": 671,
    "start_time": "2022-05-12T18:48:30.973Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-12T18:48:31.645Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-12T18:56:43.468Z"
   },
   {
    "duration": 96,
    "start_time": "2022-05-12T19:03:10.248Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-12T19:03:17.526Z"
   },
   {
    "duration": 777,
    "start_time": "2022-05-12T19:03:47.106Z"
   },
   {
    "duration": 1400402,
    "start_time": "2022-05-12T19:03:51.422Z"
   },
   {
    "duration": 4752,
    "start_time": "2022-05-13T16:26:35.140Z"
   },
   {
    "duration": 936,
    "start_time": "2022-05-13T16:26:39.895Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-13T16:26:40.834Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-13T16:26:40.893Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-13T16:26:40.898Z"
   },
   {
    "duration": 2882,
    "start_time": "2022-05-13T16:26:40.927Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:26:43.812Z"
   },
   {
    "duration": 4187,
    "start_time": "2022-05-13T16:26:43.819Z"
   },
   {
    "duration": 4077,
    "start_time": "2022-05-13T16:26:48.008Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:26:52.091Z"
   },
   {
    "duration": 121683,
    "start_time": "2022-05-13T16:26:52.097Z"
   },
   {
    "duration": 132169,
    "start_time": "2022-05-13T16:28:53.783Z"
   },
   {
    "duration": 196,
    "start_time": "2022-05-13T16:31:05.955Z"
   },
   {
    "duration": 6913,
    "start_time": "2022-05-13T16:31:06.154Z"
   },
   {
    "duration": 6641,
    "start_time": "2022-05-13T16:31:13.069Z"
   },
   {
    "duration": 6684,
    "start_time": "2022-05-13T16:31:19.713Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:31:26.399Z"
   },
   {
    "duration": 11279,
    "start_time": "2022-05-13T16:31:26.405Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-13T16:31:37.686Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-13T16:31:37.702Z"
   },
   {
    "duration": 274590,
    "start_time": "2022-05-13T16:31:37.752Z"
   },
   {
    "duration": 97320,
    "start_time": "2022-05-13T16:36:12.353Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:37:49.675Z"
   },
   {
    "duration": 6906,
    "start_time": "2022-05-13T16:37:49.682Z"
   },
   {
    "duration": 1344,
    "start_time": "2022-05-13T16:37:56.590Z"
   },
   {
    "duration": 45,
    "start_time": "2022-05-13T16:37:57.936Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:38:16.075Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-13T16:38:17.973Z"
   },
   {
    "duration": 301,
    "start_time": "2022-05-13T16:38:25.971Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:38:45.782Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-13T16:38:47.151Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-13T16:38:48.261Z"
   },
   {
    "duration": 490307,
    "start_time": "2022-05-13T16:39:13.969Z"
   },
   {
    "duration": 254122,
    "start_time": "2022-05-13T16:52:33.120Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-13T16:56:53.743Z"
   },
   {
    "duration": 176,
    "start_time": "2022-05-13T16:56:55.746Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-13T16:57:19.325Z"
   },
   {
    "duration": 84,
    "start_time": "2022-05-13T16:58:29.543Z"
   },
   {
    "duration": 4661,
    "start_time": "2022-05-13T16:58:39.551Z"
   },
   {
    "duration": 978,
    "start_time": "2022-05-13T16:58:44.215Z"
   },
   {
    "duration": 68,
    "start_time": "2022-05-13T16:58:45.196Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-13T16:58:45.270Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-13T16:58:45.280Z"
   },
   {
    "duration": 2476,
    "start_time": "2022-05-13T16:58:45.318Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:58:47.797Z"
   },
   {
    "duration": 4094,
    "start_time": "2022-05-13T16:58:47.803Z"
   },
   {
    "duration": 4081,
    "start_time": "2022-05-13T16:58:51.899Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-13T16:58:55.985Z"
   },
   {
    "duration": 135476,
    "start_time": "2022-05-13T16:58:55.990Z"
   },
   {
    "duration": 131249,
    "start_time": "2022-05-13T17:01:11.468Z"
   },
   {
    "duration": 158,
    "start_time": "2022-05-13T17:03:22.720Z"
   },
   {
    "duration": 7812,
    "start_time": "2022-05-13T17:03:22.880Z"
   },
   {
    "duration": 6775,
    "start_time": "2022-05-13T17:03:30.694Z"
   },
   {
    "duration": 6613,
    "start_time": "2022-05-13T17:03:37.472Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:03:44.088Z"
   },
   {
    "duration": 11369,
    "start_time": "2022-05-13T17:03:44.095Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-13T17:03:55.466Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-13T17:03:55.489Z"
   },
   {
    "duration": 283764,
    "start_time": "2022-05-13T17:03:55.530Z"
   },
   {
    "duration": 98760,
    "start_time": "2022-05-13T17:08:39.296Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-13T17:10:18.059Z"
   },
   {
    "duration": 7673,
    "start_time": "2022-05-13T17:10:18.065Z"
   },
   {
    "duration": 1484,
    "start_time": "2022-05-13T17:10:25.741Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-13T17:10:27.227Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-13T17:10:27.280Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-13T17:10:27.288Z"
   },
   {
    "duration": 4473,
    "start_time": "2022-05-13T17:19:38.510Z"
   },
   {
    "duration": 1001,
    "start_time": "2022-05-13T17:19:42.985Z"
   },
   {
    "duration": 70,
    "start_time": "2022-05-13T17:19:43.988Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:19:44.062Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-13T17:19:44.069Z"
   },
   {
    "duration": 2766,
    "start_time": "2022-05-13T17:19:44.123Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-13T17:19:46.891Z"
   },
   {
    "duration": 4031,
    "start_time": "2022-05-13T17:19:46.898Z"
   },
   {
    "duration": 3969,
    "start_time": "2022-05-13T17:19:50.931Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:19:54.906Z"
   },
   {
    "duration": 123863,
    "start_time": "2022-05-13T17:19:54.913Z"
   },
   {
    "duration": 118030,
    "start_time": "2022-05-13T17:21:58.778Z"
   },
   {
    "duration": 194,
    "start_time": "2022-05-13T17:23:56.810Z"
   },
   {
    "duration": 6621,
    "start_time": "2022-05-13T17:23:57.007Z"
   },
   {
    "duration": 6486,
    "start_time": "2022-05-13T17:24:03.630Z"
   },
   {
    "duration": 8180,
    "start_time": "2022-05-13T17:24:10.118Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:24:18.300Z"
   },
   {
    "duration": 11072,
    "start_time": "2022-05-13T17:24:18.306Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-13T17:24:29.380Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-13T17:24:29.398Z"
   },
   {
    "duration": 302341,
    "start_time": "2022-05-13T17:24:29.451Z"
   },
   {
    "duration": 96538,
    "start_time": "2022-05-13T17:29:31.795Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-13T17:31:08.335Z"
   },
   {
    "duration": 7593,
    "start_time": "2022-05-13T17:31:08.364Z"
   },
   {
    "duration": 1378,
    "start_time": "2022-05-13T17:31:15.962Z"
   },
   {
    "duration": 48,
    "start_time": "2022-05-13T17:31:17.343Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:31:17.393Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-13T17:31:17.401Z"
   },
   {
    "duration": 989334,
    "start_time": "2022-05-13T17:31:17.411Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-13T17:47:46.754Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-13T17:47:57.180Z"
   },
   {
    "duration": 5602,
    "start_time": "2022-05-13T17:48:44.034Z"
   },
   {
    "duration": 1460,
    "start_time": "2022-05-13T17:48:49.641Z"
   },
   {
    "duration": 69,
    "start_time": "2022-05-13T17:48:51.105Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:48:51.177Z"
   },
   {
    "duration": 45,
    "start_time": "2022-05-13T17:48:51.184Z"
   },
   {
    "duration": 2788,
    "start_time": "2022-05-13T17:48:51.232Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-13T17:48:54.022Z"
   },
   {
    "duration": 6252,
    "start_time": "2022-05-13T17:48:54.033Z"
   },
   {
    "duration": 6327,
    "start_time": "2022-05-13T17:49:00.287Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:49:06.620Z"
   },
   {
    "duration": 150420,
    "start_time": "2022-05-13T17:49:06.627Z"
   },
   {
    "duration": 150134,
    "start_time": "2022-05-13T17:51:37.052Z"
   },
   {
    "duration": 193,
    "start_time": "2022-05-13T17:54:07.188Z"
   },
   {
    "duration": 6807,
    "start_time": "2022-05-13T17:54:07.384Z"
   },
   {
    "duration": 10214,
    "start_time": "2022-05-13T17:54:14.193Z"
   },
   {
    "duration": 6715,
    "start_time": "2022-05-13T17:54:24.413Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-13T17:54:31.131Z"
   },
   {
    "duration": 10930,
    "start_time": "2022-05-13T17:54:31.152Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-13T17:54:42.084Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-13T17:54:42.100Z"
   },
   {
    "duration": 318526,
    "start_time": "2022-05-13T17:54:42.134Z"
   },
   {
    "duration": 109797,
    "start_time": "2022-05-13T18:00:00.662Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-13T18:01:50.462Z"
   },
   {
    "duration": 7535,
    "start_time": "2022-05-13T18:01:50.472Z"
   },
   {
    "duration": 1408,
    "start_time": "2022-05-13T18:01:58.009Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-13T18:01:59.419Z"
   },
   {
    "duration": 351,
    "start_time": "2022-05-13T18:01:59.483Z"
   },
   {
    "duration": 18586,
    "start_time": "2022-05-14T19:10:25.593Z"
   },
   {
    "duration": 1056,
    "start_time": "2022-05-14T19:10:44.182Z"
   },
   {
    "duration": 64,
    "start_time": "2022-05-14T19:10:45.240Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-14T19:10:45.306Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-14T19:10:45.312Z"
   },
   {
    "duration": 5263,
    "start_time": "2022-05-14T19:10:45.359Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-14T19:10:50.625Z"
   },
   {
    "duration": 3979,
    "start_time": "2022-05-14T19:10:50.634Z"
   },
   {
    "duration": 3826,
    "start_time": "2022-05-14T19:10:54.616Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-14T19:10:58.447Z"
   },
   {
    "duration": 114226,
    "start_time": "2022-05-14T19:10:58.457Z"
   },
   {
    "duration": 110602,
    "start_time": "2022-05-14T19:12:52.685Z"
   },
   {
    "duration": 163,
    "start_time": "2022-05-14T19:14:43.289Z"
   },
   {
    "duration": 6890,
    "start_time": "2022-05-14T19:14:43.454Z"
   },
   {
    "duration": 6434,
    "start_time": "2022-05-14T19:14:50.346Z"
   },
   {
    "duration": 6722,
    "start_time": "2022-05-14T19:14:56.784Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-14T19:15:03.509Z"
   },
   {
    "duration": 11153,
    "start_time": "2022-05-14T19:15:03.514Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-14T19:15:14.671Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-14T19:15:14.686Z"
   },
   {
    "duration": 253094,
    "start_time": "2022-05-14T19:15:14.718Z"
   },
   {
    "duration": 85735,
    "start_time": "2022-05-14T19:19:27.815Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-14T19:20:53.552Z"
   },
   {
    "duration": 6454,
    "start_time": "2022-05-14T19:20:53.560Z"
   },
   {
    "duration": 1313,
    "start_time": "2022-05-14T19:21:00.016Z"
   },
   {
    "duration": 46,
    "start_time": "2022-05-14T19:21:01.331Z"
   },
   {
    "duration": 602,
    "start_time": "2022-05-14T19:21:01.379Z"
   },
   {
    "duration": 1557544,
    "start_time": "2022-05-14T19:28:26.187Z"
   },
   {
    "duration": 14525,
    "start_time": "2022-05-15T10:12:14.527Z"
   },
   {
    "duration": 990,
    "start_time": "2022-05-15T10:12:29.056Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-15T10:12:30.048Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-15T10:12:30.113Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-15T10:12:30.118Z"
   },
   {
    "duration": 2332,
    "start_time": "2022-05-15T10:12:30.184Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-15T10:12:32.518Z"
   },
   {
    "duration": 3537,
    "start_time": "2022-05-15T10:12:32.532Z"
   },
   {
    "duration": 3428,
    "start_time": "2022-05-15T10:12:36.072Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-15T10:12:39.504Z"
   },
   {
    "duration": 102952,
    "start_time": "2022-05-15T10:12:39.509Z"
   },
   {
    "duration": 105528,
    "start_time": "2022-05-15T10:14:22.464Z"
   },
   {
    "duration": 160,
    "start_time": "2022-05-15T10:16:07.994Z"
   },
   {
    "duration": 5883,
    "start_time": "2022-05-15T10:16:08.156Z"
   },
   {
    "duration": 5712,
    "start_time": "2022-05-15T10:16:14.041Z"
   },
   {
    "duration": 8224,
    "start_time": "2022-05-15T10:16:19.757Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T10:16:27.984Z"
   },
   {
    "duration": 12178,
    "start_time": "2022-05-15T10:16:27.991Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-15T10:16:40.172Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-15T10:16:40.190Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-15T10:16:40.225Z"
   },
   {
    "duration": 6449,
    "start_time": "2022-05-15T10:16:40.260Z"
   },
   {
    "duration": 1229,
    "start_time": "2022-05-15T10:16:46.711Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-15T10:16:47.942Z"
   },
   {
    "duration": 528,
    "start_time": "2022-05-15T10:16:47.983Z"
   },
   {
    "duration": 1517470,
    "start_time": "2022-05-15T10:16:48.513Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T10:42:05.985Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-15T10:42:05.994Z"
   },
   {
    "duration": 390843,
    "start_time": "2022-05-15T10:42:06.003Z"
   },
   {
    "duration": 1716639,
    "start_time": "2022-05-15T11:07:09.832Z"
   },
   {
    "duration": 101,
    "start_time": "2022-05-15T11:35:46.475Z"
   },
   {
    "duration": 246009,
    "start_time": "2022-05-15T11:38:49.852Z"
   },
   {
    "duration": 543074,
    "start_time": "2022-05-15T11:52:57.290Z"
   },
   {
    "duration": 32051,
    "start_time": "2022-05-15T12:06:47.700Z"
   },
   {
    "duration": 116157,
    "start_time": "2022-05-15T12:10:31.456Z"
   },
   {
    "duration": 11554,
    "start_time": "2022-05-15T12:20:36.044Z"
   },
   {
    "duration": 853,
    "start_time": "2022-05-15T12:20:47.601Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-15T12:20:48.461Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T12:20:48.521Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-15T12:20:48.528Z"
   },
   {
    "duration": 2283,
    "start_time": "2022-05-15T12:20:48.586Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-15T12:20:50.871Z"
   },
   {
    "duration": 3741,
    "start_time": "2022-05-15T12:20:50.880Z"
   },
   {
    "duration": 3845,
    "start_time": "2022-05-15T12:20:54.623Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T12:20:58.472Z"
   },
   {
    "duration": 110211,
    "start_time": "2022-05-15T12:20:58.478Z"
   },
   {
    "duration": 107244,
    "start_time": "2022-05-15T12:22:48.691Z"
   },
   {
    "duration": 172,
    "start_time": "2022-05-15T12:24:35.937Z"
   },
   {
    "duration": 6116,
    "start_time": "2022-05-15T12:24:36.111Z"
   },
   {
    "duration": 5799,
    "start_time": "2022-05-15T12:24:42.229Z"
   },
   {
    "duration": 5949,
    "start_time": "2022-05-15T12:24:48.030Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-15T12:24:53.981Z"
   },
   {
    "duration": 267696,
    "start_time": "2022-05-15T12:24:53.989Z"
   },
   {
    "duration": 38701,
    "start_time": "2022-05-15T12:32:22.174Z"
   },
   {
    "duration": 32620,
    "start_time": "2022-05-15T12:36:22.853Z"
   },
   {
    "duration": 42888,
    "start_time": "2022-05-15T12:39:07.476Z"
   },
   {
    "duration": 39245,
    "start_time": "2022-05-15T12:40:46.524Z"
   },
   {
    "duration": 38376,
    "start_time": "2022-05-15T12:43:03.417Z"
   },
   {
    "duration": 38290,
    "start_time": "2022-05-15T12:44:04.876Z"
   },
   {
    "duration": 3831,
    "start_time": "2022-05-15T12:47:18.611Z"
   },
   {
    "duration": 861,
    "start_time": "2022-05-15T12:47:22.445Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-15T12:47:23.308Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T12:47:23.361Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-15T12:47:23.367Z"
   },
   {
    "duration": 2255,
    "start_time": "2022-05-15T12:47:23.401Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T12:47:25.658Z"
   },
   {
    "duration": 3691,
    "start_time": "2022-05-15T12:47:25.665Z"
   },
   {
    "duration": 3598,
    "start_time": "2022-05-15T12:47:29.358Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-15T12:47:32.961Z"
   },
   {
    "duration": 102199,
    "start_time": "2022-05-15T12:47:32.966Z"
   },
   {
    "duration": 100821,
    "start_time": "2022-05-15T12:49:15.167Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-15T12:50:55.990Z"
   },
   {
    "duration": 5788,
    "start_time": "2022-05-15T12:50:56.115Z"
   },
   {
    "duration": 5558,
    "start_time": "2022-05-15T12:51:01.905Z"
   },
   {
    "duration": 5698,
    "start_time": "2022-05-15T12:51:07.466Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-15T12:51:13.167Z"
   },
   {
    "duration": 13378,
    "start_time": "2022-05-15T14:22:46.577Z"
   },
   {
    "duration": 962,
    "start_time": "2022-05-15T14:22:59.958Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-15T14:23:00.923Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-15T14:23:00.983Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-15T14:23:00.988Z"
   },
   {
    "duration": 2481,
    "start_time": "2022-05-15T14:23:01.021Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-15T14:23:03.505Z"
   },
   {
    "duration": 3673,
    "start_time": "2022-05-15T14:23:03.528Z"
   },
   {
    "duration": 3606,
    "start_time": "2022-05-15T14:23:07.203Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T14:23:10.814Z"
   },
   {
    "duration": 112975,
    "start_time": "2022-05-15T14:23:10.820Z"
   },
   {
    "duration": 108842,
    "start_time": "2022-05-15T14:25:03.797Z"
   },
   {
    "duration": 138,
    "start_time": "2022-05-15T14:26:52.641Z"
   },
   {
    "duration": 6798,
    "start_time": "2022-05-15T14:26:52.781Z"
   },
   {
    "duration": 7772,
    "start_time": "2022-05-15T14:26:59.581Z"
   },
   {
    "duration": 6589,
    "start_time": "2022-05-15T14:27:07.358Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-15T14:27:13.949Z"
   },
   {
    "duration": 3526815,
    "start_time": "2022-05-15T14:27:13.962Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-15T15:33:07.689Z"
   },
   {
    "duration": 51953,
    "start_time": "2022-05-15T15:33:10.960Z"
   },
   {
    "duration": 259263,
    "start_time": "2022-05-15T15:34:02.957Z"
   },
   {
    "duration": 820,
    "start_time": "2022-05-15T15:38:22.222Z"
   },
   {
    "duration": 155611,
    "start_time": "2022-05-15T15:40:11.987Z"
   },
   {
    "duration": 39854,
    "start_time": "2022-05-15T15:42:47.602Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-15T15:43:27.465Z"
   },
   {
    "duration": 346827,
    "start_time": "2022-05-15T15:45:54.547Z"
   },
   {
    "duration": 616699,
    "start_time": "2022-05-15T15:52:21.874Z"
   },
   {
    "duration": 13707,
    "start_time": "2022-05-15T16:04:33.385Z"
   },
   {
    "duration": 971,
    "start_time": "2022-05-15T16:04:47.095Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-15T16:04:48.070Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-15T16:04:48.123Z"
   },
   {
    "duration": 56,
    "start_time": "2022-05-15T16:04:48.128Z"
   },
   {
    "duration": 2452,
    "start_time": "2022-05-15T16:04:48.186Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-15T16:04:50.640Z"
   },
   {
    "duration": 5800,
    "start_time": "2022-05-15T16:04:50.659Z"
   },
   {
    "duration": 4975,
    "start_time": "2022-05-15T16:04:56.462Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T16:05:01.441Z"
   },
   {
    "duration": 132948,
    "start_time": "2022-05-15T16:05:01.456Z"
   },
   {
    "duration": 111752,
    "start_time": "2022-05-15T16:07:14.408Z"
   },
   {
    "duration": 197,
    "start_time": "2022-05-15T16:09:06.163Z"
   },
   {
    "duration": 6233,
    "start_time": "2022-05-15T16:09:06.362Z"
   },
   {
    "duration": 6044,
    "start_time": "2022-05-15T16:09:12.598Z"
   },
   {
    "duration": 7834,
    "start_time": "2022-05-15T16:09:18.645Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-15T16:09:26.482Z"
   },
   {
    "duration": 45204,
    "start_time": "2022-05-15T16:09:26.490Z"
   },
   {
    "duration": 264646,
    "start_time": "2022-05-15T16:10:11.697Z"
   },
   {
    "duration": 792,
    "start_time": "2022-05-15T16:14:36.346Z"
   },
   {
    "duration": 808,
    "start_time": "2022-05-15T16:14:37.141Z"
   },
   {
    "duration": 320956,
    "start_time": "2022-05-15T16:14:37.956Z"
   },
   {
    "duration": 593076,
    "start_time": "2022-05-15T16:19:58.914Z"
   },
   {
    "duration": 41814,
    "start_time": "2022-05-15T16:29:51.994Z"
   },
   {
    "duration": 126,
    "start_time": "2022-05-15T16:34:42.826Z"
   },
   {
    "duration": 15386,
    "start_time": "2022-05-15T16:35:32.611Z"
   },
   {
    "duration": 1104,
    "start_time": "2022-05-15T16:35:47.999Z"
   },
   {
    "duration": 72,
    "start_time": "2022-05-15T16:35:49.106Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-15T16:35:49.182Z"
   },
   {
    "duration": 38,
    "start_time": "2022-05-15T16:35:49.189Z"
   },
   {
    "duration": 2771,
    "start_time": "2022-05-15T16:35:49.230Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-15T16:35:52.003Z"
   },
   {
    "duration": 5456,
    "start_time": "2022-05-15T16:35:52.014Z"
   },
   {
    "duration": 4684,
    "start_time": "2022-05-15T16:35:57.474Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-15T16:36:02.163Z"
   },
   {
    "duration": 119623,
    "start_time": "2022-05-15T16:36:02.179Z"
   },
   {
    "duration": 121931,
    "start_time": "2022-05-15T16:38:01.805Z"
   },
   {
    "duration": 319,
    "start_time": "2022-05-15T16:40:03.739Z"
   },
   {
    "duration": 7735,
    "start_time": "2022-05-15T16:40:04.061Z"
   },
   {
    "duration": 7977,
    "start_time": "2022-05-15T16:40:11.801Z"
   },
   {
    "duration": 7211,
    "start_time": "2022-05-15T16:40:19.781Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-15T16:40:26.994Z"
   },
   {
    "duration": 37488,
    "start_time": "2022-05-15T16:40:27.001Z"
   },
   {
    "duration": 244169,
    "start_time": "2022-05-15T16:41:04.491Z"
   },
   {
    "duration": 699,
    "start_time": "2022-05-15T16:45:08.664Z"
   },
   {
    "duration": 1806897,
    "start_time": "2022-05-15T16:45:09.368Z"
   },
   {
    "duration": 360656,
    "start_time": "2022-05-15T17:15:16.268Z"
   },
   {
    "duration": 534503,
    "start_time": "2022-05-15T17:21:16.926Z"
   },
   {
    "duration": 30639,
    "start_time": "2022-05-15T17:30:11.431Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-15T17:30:42.073Z"
   },
   {
    "duration": 48,
    "start_time": "2022-05-15T17:30:42.079Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
